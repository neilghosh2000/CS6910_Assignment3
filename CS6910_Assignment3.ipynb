{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from tensorflow.keras import  models, optimizers, layers, activations\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, RNN, GRU, Dense, Embedding\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set of hyperparameters to be tuned during the sweep\n",
    "\n",
    "default_parameters = dict(\n",
    "    embedding_size = 32,\n",
    "    batch_size = 32,\n",
    "    num_enc_layers = 3,\n",
    "    num_dec_layers = 3,\n",
    "    hidden_layer_size = 64,\n",
    "    cell_type = 'LSTM',\n",
    "    dropout = 0.2,\n",
    "    recurrent_dropout = 0.2,\n",
    "    epochs = 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: arnesh_neil (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.27 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">expert-totem-10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/arneshbose1/CS6910_Assignment3\" target=\"_blank\">https://wandb.ai/arneshbose1/CS6910_Assignment3</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/arneshbose1/CS6910_Assignment3/runs/30jgx3oh\" target=\"_blank\">https://wandb.ai/arneshbose1/CS6910_Assignment3/runs/30jgx3oh</a><br/>\n",
       "                Run data is saved locally in <code>E:\\CS6910 Assignments\\Assignment 3\\wandb\\run-20210428_110102-30jgx3oh</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb login \n",
    "run = wandb.init(config=default_parameters, project=\"CS6910_Assignment3\", entity=\"arneshbose1\")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the train, validation and test dataset\n",
    "\n",
    "train_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.train.tsv'\n",
    "val_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.dev.tsv'\n",
    "test_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.test.tsv'\n",
    "\n",
    "# creating the corpus and vectorizing the data\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "input_corpus = set()\n",
    "output_corpus = set()\n",
    "\n",
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    \n",
    "for line in lines[:len(lines) - 1]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    #using \"tab\" as the \"start sequence\" character for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    train_X.append(input_text)\n",
    "    train_Y.append(target_text)\n",
    "    for char in input_text:\n",
    "        input_corpus.add(char)\n",
    "    for char in target_text:\n",
    "        output_corpus.add(char)\n",
    "\n",
    "# ' ' is used to fill the empty spaces of shorter sequences\n",
    "input_corpus.add(\" \")\n",
    "output_corpus.add(\" \")\n",
    "input_corpus = sorted(list(input_corpus))\n",
    "output_corpus = sorted(list(output_corpus))\n",
    "num_encoder_tokens = len(input_corpus)\n",
    "num_decoder_tokens = len(output_corpus)\n",
    "max_encoder_seq_length = max([len(txt) for txt in train_X])\n",
    "max_decoder_seq_length = max([len(txt) for txt in train_Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = []\n",
    "val_Y = []\n",
    "with open(val_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    \n",
    "for line in lines[:len(lines) - 1]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    val_X.append(input_text)\n",
    "    val_Y.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 44204\n",
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 66\n",
      "Max sequence length for inputs: 20\n",
      "Max sequence length for outputs: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(train_X))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char_index = dict([(char, i) for i, char in enumerate(input_corpus)])\n",
    "output_char_index = dict([(char, i) for i, char in enumerate(output_corpus)])\n",
    "\n",
    "encoder_input_data = np.zeros((len(train_X), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "decoder_input_data = np.zeros((len(train_X), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "decoder_target_data = np.zeros((len(train_X), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "for i, (x, y) in enumerate(zip(train_X, train_Y)):\n",
    "    for t, char in enumerate(x):\n",
    "        encoder_input_data[i, t, input_char_index[char]] = 1.0\n",
    "        \n",
    "    encoder_input_data[i, t + 1 :, input_char_index[\" \"]] = 1.0\n",
    "    \n",
    "    for t, char in enumerate(y):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, output_char_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, output_char_index[char]] = 1.0\n",
    "            \n",
    "    decoder_input_data[i, t + 1 :, output_char_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, output_char_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data_val = np.zeros((len(val_X), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "decoder_input_data_val = np.zeros((len(val_X), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "decoder_target_data_val = np.zeros((len(val_X), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "for i, (x, y) in enumerate(zip(val_X, val_Y)):\n",
    "    for t, char in enumerate(x):\n",
    "        encoder_input_data_val[i, t, input_char_index[char]] = 1.0\n",
    "        \n",
    "    encoder_input_data_val[i, t + 1 :, input_char_index[\" \"]] = 1.0\n",
    "    \n",
    "    for t, char in enumerate(y):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data_val[i, t, output_char_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            decoder_target_data_val[i, t - 1, output_char_index[char]] = 1.0\n",
    "            \n",
    "    decoder_input_data_val[i, t + 1 :, output_char_index[\" \"]] = 1.0\n",
    "    decoder_target_data_val[i, t:, output_char_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(num_enc_layers,num_dec_layers, hidden_layer_size, cell_type, dropout, recurrent_dropout,\n",
    "                   num_encoder_tokens,num_decoder_tokens):\n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "        x_e = encoder_inputs\n",
    "\n",
    "        for i in range(num_enc_layers-1):\n",
    "            x_e = LSTM(hidden_layer_size, return_state=True, return_sequences=True)(x_e)\n",
    "\n",
    "        encoder_outputs, state_h, state_c = LSTM(hidden_layer_size, return_state=True)(x_e)\n",
    "\n",
    "        encoder_states = [state_h, state_c]\n",
    "\n",
    "        decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "        x_d = decoder_inputs\n",
    "\n",
    "        x_d = LSTM(hidden_layer_size, return_sequences=True, return_state=True)(x_d,initial_state=encoder_states)\n",
    "        for i in range(num_dec_layers-1):\n",
    "            x_d = LSTM(hidden_layer_size, return_sequences=True, return_state=True)(x_d)\n",
    "\n",
    "        decoder_outputs, _, _ = x_d\n",
    "        decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = config.embedding_size\n",
    "batch_size = config.batch_size\n",
    "num_enc_layers = config.num_enc_layers\n",
    "num_dec_layers = config.num_dec_layers\n",
    "hidden_layer_size = config.hidden_layer_size\n",
    "cell_type = config.cell_type\n",
    "dropout = config.dropout\n",
    "recurrent_dropout = config.recurrent_dropout\n",
    "epochs = config.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1382/1382 [==============================] - 23s 17ms/step - loss: 1.0383 - accuracy: 0.7295 - val_loss: 0.8586 - val_accuracy: 0.7710 15s - loss: 1.2758 - accur - ETA: 15s - loss: 1.2432 - ac - ETA: 14s - loss: 1.2159 - accur - ETA: 14s  - ETA: 2s - ETA: 1s - los - ETA: 0s - loss: 1.041\n",
      "Epoch 2/10\n",
      "1382/1382 [==============================] - 21s 15ms/step - loss: 0.8010 - accuracy: 0.7832 - val_loss: 0.5700 - val_accuracy: 0.8428\n",
      "Epoch 3/10\n",
      "1382/1382 [==============================] - 24s 18ms/step - loss: 0.4329 - accuracy: 0.8780 - val_loss: 0.2979 - val_accuracy: 0.9143: 18s - loss: 0.5879 - accuracy: 0.83 - ETA: 18s - loss: 0.5870 - accuracy: 0.8 - ETA: 17s  - ETA: 10s - - ETA: 5s - loss: 0.4723 - accura - ETA: 5s - loss: 0.4705 - accuracy: 0.86 - ETA - ETA: 2s - loss: 0.4496 -  - ETA: 1s - los - ETA: 1s - loss: 0.4403 - accuracy: 0. - ETA: 0s -\n",
      "Epoch 4/10\n",
      "1382/1382 [==============================] - 24s 17ms/step - loss: 0.1897 - accuracy: 0.9479 - val_loss: 0.1348 - val_accuracy: 0.9634loss: 0.2664 - accur - ETA: 19s - loss: 0.2625  - ETA: 18s - loss: 0. - ETA: 16s - loss: 0.2503 - accu - E - ETA: 13s  - ETA: 11s - loss: 0.2282 - accuracy: 0 - ETA: 7s - loss: 0.2106 - accuracy: 0. - ETA: 6s - loss: 0.2104 - accuracy: 0.94 - ETA: 6s - loss: 0.2101 - accuracy: 0. - ETA: 6s - loss: 0.2095 - accuracy: 0. - ETA: 6s - loss: 0.2091 - accura - ETA: 6s - loss: 0.208 - E - ETA: 2s - loss: 0.1979 - accu - ETA: 2s - loss: 0.1971 - ac - ETA - ETA: 1s\n",
      "Epoch 5/10\n",
      "1382/1382 [==============================] - 25s 18ms/step - loss: 0.0907 - accuracy: 0.9762 - val_loss: 0.0806 - val_accuracy: 0.9774 - \n",
      "Epoch 6/10\n",
      "1382/1382 [==============================] - 27s 19ms/step - loss: 0.0506 - accuracy: 0.9872 - val_loss: 0.0541 - val_accuracy: 0.98540.0618 - accuracy: 0 - ETA: 2\n",
      "Epoch 7/10\n",
      "1382/1382 [==============================] - 27s 19ms/step - loss: 0.0317 - accuracy: 0.9922 - val_loss: 0.0363 - val_accuracy: 0.9904372 - accuracy - ETA: 21s - loss: 0.0372 - accuracy: 0.9 - ETA: 20s - loss: 0.0369 - accuracy: - ETA: 20s - los - ETA: 14s - loss: 0.0352 - - ETA: - ETA: - ETA: 3s - loss: 0.0324 - accura - ETA: 1s - loss: 0.0319 - accuracy - ETA: 1s - loss: 0.0319 - accura - ETA: 1s - loss: 0.0318 - ac - ETA: 0s - loss: 0.0318 - accu - ETA: 0s - loss: 0.0317 - accura\n",
      "Epoch 8/10\n",
      "1382/1382 [==============================] - 26s 19ms/step - loss: 0.0215 - accuracy: 0.9948 - val_loss: 0.0157 - val_accuracy: 0.9963- ETA: 19s - - ETA: 18s - loss: 0.0243 - accuracy:  - ET - ETA: 15s - loss: 0.0243 - ac - ETA: 14s - loss: 0.0240 - - ETA: 13s - los - ETA: 12s - ETA: 0s - loss: 0.0216 - accura\n",
      "Epoch 9/10\n",
      "1382/1382 [==============================] - 32s 23ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.0139 - val_accuracy: 0.9967- E\n",
      "Epoch 10/10\n",
      "1382/1382 [==============================] - 37s 27ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 0.0140 - val_accuracy: 0.9963 - loss:  - ETA: 10s - loss: 0.0122 -  - ETA: 9s - loss: 0.0122 - E - ETA: 3s - l - ETA: 1s - loss: 0.0118 - accu - ETA: 0s - l\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2732260a7c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = training_model(num_enc_layers,num_dec_layers, hidden_layer_size, cell_type, dropout, recurrent_dropout,\n",
    "                   num_encoder_tokens,num_decoder_tokens)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit([encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=([encoder_input_data_val, decoder_input_data_val],decoder_target_data_val),\n",
    "    callbacks=[WandbCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None, 27)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, None, 64), ( 23552       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 64), ( 33024       lstm_5[0][0]                     \n",
      "                                                                 lstm_5[0][1]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None, 66)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 64), (None,  33024       lstm_6[0][0]                     \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, None, 64), ( 33536       input_4[0][0]                    \n",
      "                                                                 lstm_7[0][1]                     \n",
      "                                                                 lstm_7[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, None, 64), ( 33024       lstm_8[0][0]                     \n",
      "                                                                 lstm_8[0][1]                     \n",
      "                                                                 lstm_8[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, None, 64), ( 33024       lstm_9[0][0]                     \n",
      "                                                                 lstm_9[0][1]                     \n",
      "                                                                 lstm_9[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 66)     4290        lstm_10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 193,474\n",
      "Trainable params: 193,474\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[4].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = Input(shape=(hidden_layer_size,), name=\"input_3\")\n",
    "decoder_state_input_c = Input(shape=(hidden_layer_size,), name=\"input_5\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm_1 = model.layers[5]\n",
    "decoder_lstm_2 = model.layers[6]\n",
    "decoder_lstm_3 = model.layers[7]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm_3(decoder_lstm_2(decoder_lstm_1(decoder_inputs, initial_state=decoder_states_inputs)))\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[8]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_char_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in output_char_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None, 27)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, None, 64), ( 23552       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 64), ( 33024       lstm_5[0][0]                     \n",
      "                                                                 lstm_5[0][1]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 64), (None,  33024       lstm_6[0][0]                     \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "==================================================================================================\n",
      "Total params: 89,600\n",
      "Trainable params: 89,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, 66)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, None, 64), ( 33536       input_4[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, None, 64), ( 33024       lstm_8[3][0]                     \n",
      "                                                                 lstm_8[3][1]                     \n",
      "                                                                 lstm_8[3][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, None, 64), ( 33024       lstm_9[3][0]                     \n",
      "                                                                 lstm_9[3][1]                     \n",
      "                                                                 lstm_9[3][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 66)     4290        lstm_10[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 103,874\n",
      "Trainable params: 103,874\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, output_char_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: an\n",
      "Decoded sentence: ्ंभ््  ोोट्यांघरांभ्  \n",
      "-\n",
      "Input sentence: ankganit\n",
      "Decoded sentence: ्ंत् ांत्र\n",
      "\n",
      "-\n",
      "Input sentence: uncle\n",
      "Decoded sentence: ्ंभ््\n",
      "\n",
      "-\n",
      "Input sentence: ankur\n",
      "Decoded sentence: ्डग्राांत् म्ओभ्ांत्  \n",
      "-\n",
      "Input sentence: ankuran\n",
      "Decoded sentence: ्लग्रा\n",
      "\n",
      "-\n",
      "Input sentence: ankurit\n",
      "Decoded sentence: ्लग्रा\n",
      "\n",
      "-\n",
      "Input sentence: aankush\n",
      "Decoded sentence: ्एभ्एमाणरांभ् माोगराीग\n",
      "-\n",
      "Input sentence: ankush\n",
      "Decoded sentence: ्ंत्  ोंत्आ\n",
      "\n",
      "-\n",
      "Input sentence: ang\n",
      "Decoded sentence: ्ंभ््\n",
      "\n",
      "-\n",
      "Input sentence: anga\n",
      "Decoded sentence: ्ंभ््\n",
      "\n",
      "-\n",
      "Input sentence: agandh\n",
      "Decoded sentence: ्डल्र\n",
      "\n",
      "-\n",
      "Input sentence: angad\n",
      "Decoded sentence: ्डग्राोंत् ोंत्ी\n",
      "\n",
      "-\n",
      "Input sentence: angane\n",
      "Decoded sentence: ्ंभ््\n",
      "\n",
      "-\n",
      "Input sentence: angbhang\n",
      "Decoded sentence: ीगेत्\n",
      "\n",
      "-\n",
      "Input sentence: angarakshak\n",
      "Decoded sentence: ीगृथाोगराोगधाांभराीगरा\n",
      "-\n",
      "Input sentence: angrakshak\n",
      "Decoded sentence: ीग्ठा्लराोगराीगध्ा\n",
      "\n",
      "-\n",
      "Input sentence: angara\n",
      "Decoded sentence: ्डग्राांध्ा\n",
      "\n",
      "-\n",
      "Input sentence: angaare\n",
      "Decoded sentence: ्डग्राांध्ा\n",
      "\n",
      "-\n",
      "Input sentence: angare\n",
      "Decoded sentence: ्डग्राांध्ा\n",
      "\n",
      "-\n",
      "Input sentence: angi\n",
      "Decoded sentence: ्ंभ््\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(20):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", train_X[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
