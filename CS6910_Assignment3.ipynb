{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from tensorflow.keras import  models, optimizers, layers, activations\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, RNN, GRU, Dense, Embedding\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set of hyperparameters to be tuned during the sweep\n",
    "\n",
    "default_parameters = dict(\n",
    "    embedding_size = 32,\n",
    "    batch_size = 32,\n",
    "    num_enc_layers = 2,\n",
    "    num_dec_layers = 2,\n",
    "    hidden_layer_size = 64,\n",
    "    cell_type = 'LSTM',\n",
    "    dropout = 0.2,\n",
    "    recurrent_dropout = 0.2,\n",
    "    epochs = 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.27 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">apricot-mountain-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/arneshbose1/CS6910_Assignment3\" target=\"_blank\">https://wandb.ai/arneshbose1/CS6910_Assignment3</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/arneshbose1/CS6910_Assignment3/runs/2du81iza\" target=\"_blank\">https://wandb.ai/arneshbose1/CS6910_Assignment3/runs/2du81iza</a><br/>\n",
       "                Run data is saved locally in <code>E:\\CS6910 Assignments\\Assignment 3\\wandb\\run-20210428_190107-2du81iza</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb login \n",
    "run = wandb.init(config=default_parameters, project=\"CS6910_Assignment3\", entity=\"arneshbose1\")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the train, validation and test dataset\n",
    "\n",
    "train_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.train.tsv'\n",
    "val_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.dev.tsv'\n",
    "test_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.test.tsv'\n",
    "\n",
    "# creating the corpus and vectorizing the data\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "input_corpus = set()\n",
    "output_corpus = set()\n",
    "\n",
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    \n",
    "for line in lines[:len(lines) - 1]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    #using \"tab\" as the \"start sequence\" character for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    train_X.append(input_text)\n",
    "    train_Y.append(target_text)\n",
    "    for char in input_text:\n",
    "        input_corpus.add(char)\n",
    "    for char in target_text:\n",
    "        output_corpus.add(char)\n",
    "\n",
    "# ' ' is used to fill the empty spaces of shorter sequences\n",
    "input_corpus.add(\" \")\n",
    "output_corpus.add(\" \")\n",
    "input_corpus = sorted(list(input_corpus))\n",
    "output_corpus = sorted(list(output_corpus))\n",
    "num_encoder_tokens = len(input_corpus)\n",
    "num_decoder_tokens = len(output_corpus)\n",
    "max_encoder_seq_length = max([len(txt) for txt in train_X])\n",
    "max_decoder_seq_length = max([len(txt) for txt in train_Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = []\n",
    "val_Y = []\n",
    "with open(val_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    \n",
    "for line in lines[:len(lines) - 1]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    val_X.append(input_text)\n",
    "    val_Y.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 44204\n",
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 66\n",
      "Max sequence length for inputs: 20\n",
      "Max sequence length for outputs: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(train_X))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char_index = dict([(char, i) for i, char in enumerate(input_corpus)])\n",
    "output_char_index = dict([(char, i) for i, char in enumerate(output_corpus)])\n",
    "\n",
    "encoder_input_data = np.zeros((len(train_X), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "decoder_input_data = np.zeros((len(train_X), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "decoder_target_data = np.zeros((len(train_X), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "for i, (x, y) in enumerate(zip(train_X, train_Y)):\n",
    "    for t, char in enumerate(x):\n",
    "        encoder_input_data[i, t, input_char_index[char]] = 1.0\n",
    "        \n",
    "    encoder_input_data[i, t + 1 :, input_char_index[\" \"]] = 1.0\n",
    "    \n",
    "    for t, char in enumerate(y):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, output_char_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, output_char_index[char]] = 1.0\n",
    "            \n",
    "    decoder_input_data[i, t + 1 :, output_char_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, output_char_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data_val = np.zeros((len(val_X), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "decoder_input_data_val = np.zeros((len(val_X), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "decoder_target_data_val = np.zeros((len(val_X), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
    "\n",
    "for i, (x, y) in enumerate(zip(val_X, val_Y)):\n",
    "    for t, char in enumerate(x):\n",
    "        encoder_input_data_val[i, t, input_char_index[char]] = 1.0\n",
    "        \n",
    "    encoder_input_data_val[i, t + 1 :, input_char_index[\" \"]] = 1.0\n",
    "    \n",
    "    for t, char in enumerate(y):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data_val[i, t, output_char_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            decoder_target_data_val[i, t - 1, output_char_index[char]] = 1.0\n",
    "            \n",
    "    decoder_input_data_val[i, t + 1 :, output_char_index[\" \"]] = 1.0\n",
    "    decoder_target_data_val[i, t:, output_char_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(num_enc_layers,num_dec_layers, hidden_layer_size, cell_type, dropout, recurrent_dropout,\n",
    "                   num_encoder_tokens,num_decoder_tokens):\n",
    "    \n",
    "    if cell_type == 'LSTM':\n",
    "        encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "        x_e = encoder_inputs\n",
    "\n",
    "        for i in range(num_enc_layers-1):\n",
    "            x_e = LSTM(hidden_layer_size, return_state=True, return_sequences=True)(x_e)\n",
    "\n",
    "        encoder_outputs, state_h, state_c = LSTM(hidden_layer_size, return_state=True)(x_e)\n",
    "\n",
    "        encoder_states = [state_h, state_c]\n",
    "\n",
    "        decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "        x_d = decoder_inputs\n",
    "\n",
    "        x_d = LSTM(hidden_layer_size, return_sequences=True, return_state=True)(x_d,initial_state=encoder_states)\n",
    "        for i in range(num_dec_layers-1):\n",
    "            x_d = LSTM(hidden_layer_size, return_sequences=True, return_state=True)(x_d)\n",
    "\n",
    "        decoder_outputs, _, _ = x_d\n",
    "        decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = config.embedding_size\n",
    "batch_size = config.batch_size\n",
    "num_enc_layers = config.num_enc_layers\n",
    "num_dec_layers = config.num_dec_layers\n",
    "hidden_layer_size = config.hidden_layer_size\n",
    "cell_type = config.cell_type\n",
    "dropout = config.dropout\n",
    "recurrent_dropout = config.recurrent_dropout\n",
    "epochs = config.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = training_model(num_enc_layers,num_dec_layers, hidden_layer_size, cell_type, dropout, recurrent_dropout,\n",
    "                   num_encoder_tokens,num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1382/1382 [==============================] - 19s 13ms/step - loss: 0.9923 - accuracy: 0.7431 - val_loss: 0.7397 - val_accuracy: 0.8009\n",
      "Epoch 2/10\n",
      "1382/1382 [==============================] - 18s 13ms/step - loss: 0.5883 - accuracy: 0.8375 - val_loss: 0.4361 - val_accuracy: 0.8766ETA: 0s - loss:\n",
      "Epoch 3/10\n",
      "1382/1382 [==============================] - 19s 14ms/step - loss: 0.3062 - accuracy: 0.9133 - val_loss: 0.2164 - val_accuracy: 0.9403\n",
      "Epoch 4/10\n",
      "1382/1382 [==============================] - 20s 14ms/step - loss: 0.1514 - accuracy: 0.9588 - val_loss: 0.1209 - val_accuracy: 0.9661\n",
      "Epoch 5/10\n",
      "1382/1382 [==============================] - 20s 15ms/step - loss: 0.0821 - accuracy: 0.9785 - val_loss: 0.0635 - val_accuracy: 0.9837\n",
      "Epoch 6/10\n",
      "1382/1382 [==============================] - 21s 15ms/step - loss: 0.0507 - accuracy: 0.9871 - val_loss: 0.0472 - val_accuracy: 0.98731 - accura - ETA: 0s - loss: 0.050\n",
      "Epoch 7/10\n",
      "1382/1382 [==============================] - 22s 16ms/step - loss: 0.0348 - accuracy: 0.9911 - val_loss: 0.0307 - val_accuracy: 0.9916 14s  - ETA: 13s - l - ETA: 9s - loss: - ETA: 8s - loss: 0.0371 - accuracy:  - ETA:  - ETA:  - ETA: 1s - ETA: 0s - loss: 0.0349 - accuracy: 0.99 - ETA: 0s - loss: 0.0348 - accu\n",
      "Epoch 8/10\n",
      "1382/1382 [==============================] - 22s 16ms/step - loss: 0.0253 - accuracy: 0.9937 - val_loss: 0.0336 - val_accuracy: 0.9907: 0.0265 - ac - ETA: 8s - loss: 0.0263 - accuracy - ETA: 8s - loss: 0.0262 - accuracy: 0.99 - ETA: 8s - loss: 0.0262 -  - ETA: 6s - los - ETA: 1s - ETA: 0s - loss: 0.025 - ETA: 0s - loss: 0.0253 - accuracy\n",
      "Epoch 9/10\n",
      "1382/1382 [==============================] - 23s 17ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.0176 - val_accuracy: 0.9956 loss: 0.0209 - accurac - ETA: 19s - loss: 0 - ETA: 3s - los - ETA: 0s - loss: 0.0194 - accura\n",
      "Epoch 10/10\n",
      "1382/1382 [==============================] - 23s 17ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.0278 - val_accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x164a1dc0eb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit([encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=([encoder_input_data_val, decoder_input_data_val],decoder_target_data_val),\n",
    "    callbacks=[WandbCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 27)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, None, 64), ( 23552       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 66)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       lstm[0][0]                       \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 64), ( 33536       input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 64), ( 33024       lstm_2[0][0]                     \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 66)     4290        lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 127,426\n",
      "Trainable params: 127,426\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[num_enc_layers+1].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = Input(shape=(hidden_layer_size,), name=\"input_3\")\n",
    "decoder_state_input_c = Input(shape=(hidden_layer_size,), name=\"input_5\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm = model.layers[num_enc_layers+2]\n",
    "decoder_x = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "for i in range(num_dec_layers-1):\n",
    "    decoder_lstm = model.layers[num_enc_layers+3+i]\n",
    "    decoder_x = decoder_lstm(decoder_x)\n",
    "    \n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_x\n",
    "    \n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[num_enc_layers+num_dec_layers+2]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_char_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in output_char_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 27)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, None, 64), ( 23552       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       lstm[0][0]                       \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "==================================================================================================\n",
      "Total params: 56,576\n",
      "Trainable params: 56,576\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 66)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 64), ( 33536       input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 64), ( 33024       lstm_2[1][0]                     \n",
      "                                                                 lstm_2[1][1]                     \n",
      "                                                                 lstm_2[1][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 66)     4290        lstm_3[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 70,850\n",
      "Trainable params: 70,850\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, output_char_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: an\n",
      "Decoded sentence: हर्युपवा\n",
      "\n",
      "-\n",
      "Input sentence: ankganit\n",
      "Decoded sentence: ारहनी्लसांतमाल्सल्कराह\n",
      "-\n",
      "Input sentence: uncle\n",
      "Decoded sentence: हरकिहोपवा्पतेंलरल्सलर्\n",
      "-\n",
      "Input sentence: ankur\n",
      "Decoded sentence: हरिपर्पवेरय्रल्सालत्रक\n",
      "-\n",
      "Input sentence: ankuran\n",
      "Decoded sentence: हरोपत्ेका्रलेंदसा्लतें\n",
      "-\n",
      "Input sentence: ankurit\n",
      "Decoded sentence: ्रचनांलसाफता्खतांताफवे\n",
      "-\n",
      "Input sentence: aankush\n",
      "Decoded sentence: हरिपहारयि\n",
      "\n",
      "-\n",
      "Input sentence: ankush\n",
      "Decoded sentence: हरकोंयसा्फलसारोकहांता्\n",
      "-\n",
      "Input sentence: ang\n",
      "Decoded sentence: हरोपे्ले्कांरयदांतया्ख\n",
      "-\n",
      "Input sentence: anga\n",
      "Decoded sentence: हरग्नवोपास्लत्ता्ते्लव\n",
      "-\n",
      "Input sentence: agandh\n",
      "Decoded sentence: एदरहनेपााय्छनाल्पवारल्\n",
      "-\n",
      "Input sentence: angad\n",
      "Decoded sentence: हरग्नत्\n",
      "\n",
      "-\n",
      "Input sentence: angane\n",
      "Decoded sentence: हरग्नर्येपवात्रलसांलरय\n",
      "-\n",
      "Input sentence: angbhang\n",
      "Decoded sentence: ांखसांकाहतािफवेरंतायेत\n",
      "-\n",
      "Input sentence: angarakshak\n",
      "Decoded sentence: ंजपा्पता्ग्ले्ते्गताित\n",
      "-\n",
      "Input sentence: angrakshak\n",
      "Decoded sentence: ंरलस्नद्ीलहसीक्पतांताञ\n",
      "-\n",
      "Input sentence: angara\n",
      "Decoded sentence: हरोपर्ल्सेरदायट्नल्कवा\n",
      "-\n",
      "Input sentence: angaare\n",
      "Decoded sentence: हरोपर्येता्कवेंखतांदया\n",
      "-\n",
      "Input sentence: angare\n",
      "Decoded sentence: आनफरताता्मद्ीलसुरल्पात\n",
      "-\n",
      "Input sentence: angi\n",
      "Decoded sentence: आनफफाटन्पताारलषंरल्येर\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(20):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", train_X[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
