{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the train, validation and test dataset\n",
    "\n",
    "train_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.train.tsv'\n",
    "val_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.dev.tsv'\n",
    "test_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.test.tsv'\n",
    "\n",
    "# creating the corpus and vectorizing the data\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "input_corpus = set()\n",
    "output_corpus = set()\n",
    "\n",
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    \n",
    "for line in lines[:len(lines) - 1]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    #using \"tab\" as the \"start sequence\" character for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    train_X.append(input_text)\n",
    "    train_Y.append(target_text)\n",
    "    for char in input_text:\n",
    "        input_corpus.add(char)\n",
    "    for char in target_text:\n",
    "        output_corpus.add(char)\n",
    "\n",
    "# ' ' is used to fill the empty spaces of shorter sequences\n",
    "input_corpus.add(\" \")\n",
    "output_corpus.add(\" \")\n",
    "input_corpus = sorted(list(input_corpus))\n",
    "output_corpus = sorted(list(output_corpus))\n",
    "num_encoder_tokens = len(input_corpus)\n",
    "num_decoder_tokens = len(output_corpus)\n",
    "max_encoder_seq_length = max([len(txt) for txt in train_X])\n",
    "max_decoder_seq_length = max([len(txt) for txt in train_Y])\n",
    "\n",
    "val_X = []\n",
    "val_Y = []\n",
    "with open(val_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    \n",
    "for line in lines[:len(lines) - 1]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    val_X.append(input_text)\n",
    "    val_Y.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 44204\n",
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 66\n",
      "Max sequence length for inputs: 20\n",
      "Max sequence length for outputs: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(train_X))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char_index = dict([(char, i) for i, char in enumerate(input_corpus)])\n",
    "output_char_index = dict([(char, i) for i, char in enumerate(output_corpus)])\n",
    "\n",
    "input_data = np.zeros((max_encoder_seq_length,len(train_X)), dtype=\"int64\")\n",
    "target_data = np.zeros((max_decoder_seq_length,len(train_X)), dtype=\"int64\")\n",
    "\n",
    "for i, (x, y) in enumerate(zip(train_X, train_Y)):\n",
    "    for t, char in enumerate(x):\n",
    "        input_data[t, i] = input_char_index[char]\n",
    "        \n",
    "    input_data[t + 1 :,i] = input_char_index[\" \"]\n",
    "    \n",
    "    for t, char in enumerate(y):\n",
    "        target_data[t, i] = output_char_index[char]\n",
    "            \n",
    "    target_data[t + 1 :,i] = output_char_index[\" \"]\n",
    "    \n",
    "input_data_val = np.zeros((max_encoder_seq_length,len(val_X)), dtype=\"int64\")\n",
    "target_data_val = np.zeros((max_decoder_seq_length,len(val_X)), dtype=\"int64\")\n",
    "\n",
    "for i, (x, y) in enumerate(zip(val_X, val_Y)):\n",
    "    for t, char in enumerate(x):\n",
    "        input_data_val[t, i] = input_char_index[char]\n",
    "        \n",
    "    input_data_val[t + 1 :,i] = input_char_index[\" \"]\n",
    "    \n",
    "    for t, char in enumerate(y):\n",
    "        target_data_val[t, i] = output_char_index[char]\n",
    "            \n",
    "    target_data_val[t + 1 :,i] = output_char_index[\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertin numpy arrays to tensors\n",
    "input_data = torch.tensor(input_data,dtype=torch.int64)\n",
    "target_data = torch.tensor(target_data,dtype=torch.int64)\n",
    "input_data_val = torch.tensor(input_data_val,dtype=torch.int64)\n",
    "target_data_val = torch.tensor(target_data_val,dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = num_decoder_tokens\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "input_size_encoder = num_encoder_tokens\n",
    "input_size_decoder = num_decoder_tokens\n",
    "output_size = num_decoder_tokens\n",
    "encoder_embedding_size = 64\n",
    "decoder_embedding_size = 64\n",
    "hidden_size = 128  # Needs to be the same for both RNN's\n",
    "num_enc_layers = 3\n",
    "num_dec_layers = 3\n",
    "enc_dropout = 0.1\n",
    "dec_dropout = 0.1\n",
    "training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_enc_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_dec_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is only for training, not to be used now as we have saved the model\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_ds_x = torch.split(input_data,batch_size,dim=1)\n",
    "train_ds_y = torch.split(target_data,batch_size,dim=1)\n",
    "input_data_val = input_data_val.to(device)\n",
    "target_data_val = target_data_val.to(device)\n",
    "target_val = target_data_val[1:].reshape(-1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    model.eval()\n",
    "    model.train()\n",
    "\n",
    "    for i, (x,y) in enumerate(zip(train_ds_x,train_ds_y)):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = x.to(device)\n",
    "        target = y.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin. While we're at it\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "torch.save(model.state_dict(),'models\\model_pytorch_noAT_state.pt')\n",
    "torch.save(model,'models\\model_pytorch_noAT.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (embedding): Embedding(27, 64)\n",
       "    (rnn): LSTM(64, 128, num_layers=3, dropout=0.1)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (embedding): Embedding(66, 64)\n",
       "    (rnn): LSTM(64, 128, num_layers=3, dropout=0.1)\n",
       "    (fc): Linear(in_features=128, out_features=66, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models\\model_pytorch_noAT_state.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_char_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in output_char_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, word, input_char_index, output_char_index, reverse_input_char_index, \n",
    "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
    "              num_encoder_tokens, num_decoder_tokens, device):\n",
    "    \n",
    "    word_t = ''\n",
    "    data = np.zeros((max_encoder_seq_length,1), dtype=\"int64\")\n",
    "    for t, char in enumerate(word):\n",
    "        data[t, 0] = input_char_index[char]\n",
    "        \n",
    "    data[t + 1 :,0] = input_char_index[\" \"]\n",
    "    \n",
    "    data = torch.tensor(data,dtype=torch.int64).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(data)\n",
    "        \n",
    "    x = torch.tensor(np.array(output_char_index['\\t']).reshape(1,)).to(device)\n",
    "\n",
    "    for t in range(1, max_decoder_seq_length):\n",
    "        output, hidden, cell = model.decoder(x, hidden, cell)\n",
    "        best_guess = output.argmax(1)\n",
    "        x = best_guess\n",
    "        ch = reverse_target_char_index[x.item()]\n",
    "        if ch == '\\n':\n",
    "            break\n",
    "        else:\n",
    "            word_t = word_t+ch\n",
    "\n",
    "    return word_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tअं\n",
      "\n",
      "अं\n",
      "\tअंकगणित\n",
      "\n",
      "अंकगणित\n",
      "\tअंकल\n",
      "\n",
      "अंकल\n",
      "\tअंकुर\n",
      "\n",
      "अंकुर\n",
      "\tअंकुरण\n",
      "\n",
      "अंकुरण\n",
      "\tअंकुरित\n",
      "\n",
      "अंकुरित\n",
      "\tअंकुश\n",
      "\n",
      "आंकुश\n",
      "\tअंकुश\n",
      "\n",
      "अंकुश\n",
      "\tअंग\n",
      "\n",
      "आंग\n",
      "\tअंग\n",
      "\n",
      "अंगा\n",
      "\tअंगद\n",
      "\n",
      "अगंध\n",
      "\tअंगद\n",
      "\n",
      "अंगद\n",
      "\tअंगने\n",
      "\n",
      "अंगने\n",
      "\tअंगभंग\n",
      "\n",
      "अंगभंग\n",
      "\tअंगरक्षक\n",
      "\n",
      "अंगरक्षक\n",
      "\tअंगरक्षक\n",
      "\n",
      "अंगरक्षक\n",
      "\tअंगारा\n",
      "\n",
      "अंगारा\n",
      "\tअंगारे\n",
      "\n",
      "अंगारे\n",
      "\tअंगारे\n",
      "\n",
      "अंगारे\n",
      "\tअंगी\n",
      "\n",
      "अंगी\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(train_Y[i])\n",
    "    print(translate(model, train_X[i], input_char_index, output_char_index, reverse_input_char_index, \n",
    "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
    "              num_encoder_tokens, num_decoder_tokens, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []\n",
    "test_Y = []\n",
    "with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    \n",
    "for line in lines[:len(lines) - 1]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    test_X.append(input_text)\n",
    "    test_Y.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_test = np.zeros((max_encoder_seq_length,len(test_X)), dtype=\"int64\")\n",
    "target_data_test = np.zeros((max_decoder_seq_length,len(test_X)), dtype=\"int64\")\n",
    "\n",
    "for i, (x, y) in enumerate(zip(test_X, test_Y)):\n",
    "    for t, char in enumerate(x):\n",
    "        input_data_test[t, i] = input_char_index[char]\n",
    "        \n",
    "    input_data_test[t + 1 :,i] = input_char_index[\" \"]\n",
    "    \n",
    "    for t, char in enumerate(y):\n",
    "        target_data_test[t, i] = output_char_index[char]\n",
    "            \n",
    "    target_data_test[t + 1 :,i] = output_char_index[\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_test = torch.tensor(input_data_test,dtype=torch.int64)\n",
    "target_data_test = torch.tensor(target_data_test,dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence:  taapti\n",
      "Correct Ouput:  ताप्ती\n",
      "Decoded sentence: आतपति\n",
      "\n",
      "\n",
      "Input Sequence:  yashpaal\n",
      "Correct Ouput:  यशपाल\n",
      "Decoded sentence: यशपाल\n",
      "\n",
      "\n",
      "Input Sequence:  darra\n",
      "Correct Ouput:  दर्रा\n",
      "Decoded sentence: आरारा\n",
      "\n",
      "\n",
      "Input Sequence:  halla\n",
      "Correct Ouput:  हल्ला\n",
      "Decoded sentence: हल्ला\n",
      "\n",
      "\n",
      "Input Sequence:  emily\n",
      "Correct Ouput:  एमिल\n",
      "Decoded sentence: इमिली\n",
      "\n",
      "\n",
      "Input Sequence:  rajman\n",
      "Correct Ouput:  राजमां\n",
      "Decoded sentence: साम्मान\n",
      "\n",
      "\n",
      "Input Sequence:  dinaank\n",
      "Correct Ouput:  दिनांक\n",
      "Decoded sentence: सिनांक\n",
      "\n",
      "\n",
      "Input Sequence:  chatushkoniya\n",
      "Correct Ouput:  चतुष्कोणीय\n",
      "Decoded sentence: छटुटुकायिया\n",
      "\n",
      "\n",
      "Input Sequence:  radical\n",
      "Correct Ouput:  रैडिकल\n",
      "Decoded sentence: सेडिकल\n",
      "\n",
      "\n",
      "Input Sequence:  caitlyn\n",
      "Correct Ouput:  कैटलिन\n",
      "Decoded sentence: सैटििन\n",
      "\n",
      "\n",
      "Input Sequence:  teekamgarh\n",
      "Correct Ouput:  टीकमगढ़\n",
      "Decoded sentence: सीकमगढ़\n",
      "\n",
      "\n",
      "Input Sequence:  gahmagahmi\n",
      "Correct Ouput:  गहमागहमी\n",
      "Decoded sentence: अहहहगममी\n",
      "\n",
      "\n",
      "Input Sequence:  thirty\n",
      "Correct Ouput:  थर्टी\n",
      "Decoded sentence: हित्ती\n",
      "\n",
      "\n",
      "Input Sequence:  yari\n",
      "Correct Ouput:  यारी\n",
      "Decoded sentence: यारी\n",
      "\n",
      "\n",
      "Input Sequence:  kochi\n",
      "Correct Ouput:  कोच्चि\n",
      "Decoded sentence: सोची\n",
      "\n",
      "\n",
      "Input Sequence:  reshe\n",
      "Correct Ouput:  रेशे\n",
      "Decoded sentence: सेशे\n",
      "\n",
      "\n",
      "Input Sequence:  aaryika\n",
      "Correct Ouput:  आर्यिका\n",
      "Decoded sentence: आर्याका\n",
      "\n",
      "\n",
      "Input Sequence:  teap\n",
      "Correct Ouput:  टिप\n",
      "Decoded sentence: सीप\n",
      "\n",
      "\n",
      "Input Sequence:  gazipur\n",
      "Correct Ouput:  गाजीपुर\n",
      "Decoded sentence: आजीजपुर\n",
      "\n",
      "\n",
      "Input Sequence:  ghumakkadi\n",
      "Correct Ouput:  घुमक्कड़ी\n",
      "Decoded sentence: हुमाककड़ी\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in range(20):\n",
    "    i = np.random.randint(len(test_X))\n",
    "    print(\"Input Sequence: \", test_X[i])\n",
    "    print(\"Correct Ouput: \", test_Y[i][1:-1])\n",
    "    print(\"Decoded sentence:\", translate(model, test_X[i], input_char_index, output_char_index, reverse_input_char_index, \n",
    "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
    "              num_encoder_tokens, num_decoder_tokens, device))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4502"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azhar\n"
     ]
    }
   ],
   "source": [
    "i = 51\n",
    "print(test_X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'अजहर'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y[i][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "हुमाककड़ी\n"
     ]
    }
   ],
   "source": [
    "decoded_sentence = translate(model, test_X[i], input_char_index, output_char_index, reverse_input_char_index, \n",
    "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
    "              num_encoder_tokens, num_decoder_tokens, device)\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Word</th>\n",
       "      <th>Correct Output</th>\n",
       "      <th>Decoded Word</th>\n",
       "      <th>Exact Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jaiban</td>\n",
       "      <td>जयबाण</td>\n",
       "      <td>एयाबान</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jaankaron</td>\n",
       "      <td>जानकारों</td>\n",
       "      <td>आनंकरों</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ria</td>\n",
       "      <td>रिया</td>\n",
       "      <td>सिया</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chaudhavan</td>\n",
       "      <td>चौदहवां</td>\n",
       "      <td>छौदावण</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nazeem</td>\n",
       "      <td>नजीम</td>\n",
       "      <td>अजीमी</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>two</td>\n",
       "      <td>टु</td>\n",
       "      <td>आटचीओ</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dhuan</td>\n",
       "      <td>धुआं</td>\n",
       "      <td>उठान</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nasim</td>\n",
       "      <td>नसीम</td>\n",
       "      <td>आसीम</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gomke</td>\n",
       "      <td>गोमके</td>\n",
       "      <td>उमोके</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chadhne</td>\n",
       "      <td>चढ़ने</td>\n",
       "      <td>चढ़ने</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>saanketika</td>\n",
       "      <td>सांकेतिक</td>\n",
       "      <td>सांचकेतिता</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>farmion</td>\n",
       "      <td>फर्मिऑन</td>\n",
       "      <td>आर्मिशन</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>harana</td>\n",
       "      <td>हारना</td>\n",
       "      <td>हराना</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>asaamnjsy</td>\n",
       "      <td>असामंजस्य</td>\n",
       "      <td>आसामंस्य</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>polishing</td>\n",
       "      <td>पॉलिशिंग</td>\n",
       "      <td>सोलिशिंग</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>niptaaraa</td>\n",
       "      <td>निपटारा</td>\n",
       "      <td>इनिपतारा</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>robin</td>\n",
       "      <td>राबिन</td>\n",
       "      <td>सोबिन</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rigs</td>\n",
       "      <td>रिग्स</td>\n",
       "      <td>सिग्स</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>airway</td>\n",
       "      <td>एयरवे</td>\n",
       "      <td>इयरवे</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>garjana</td>\n",
       "      <td>गर्जना</td>\n",
       "      <td>उल्जना</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Input Word Correct Output Decoded Word Exact Match\n",
       "0       jaiban          जयबाण       एयाबान          No\n",
       "1    jaankaron       जानकारों      आनंकरों          No\n",
       "2          ria           रिया         सिया          No\n",
       "3   chaudhavan        चौदहवां       छौदावण          No\n",
       "4       nazeem           नजीम        अजीमी          No\n",
       "5          two             टु        आटचीओ          No\n",
       "6        dhuan           धुआं         उठान          No\n",
       "7        nasim           नसीम         आसीम          No\n",
       "8        gomke          गोमके        उमोके          No\n",
       "9      chadhne          चढ़ने        चढ़ने         Yes\n",
       "10  saanketika       सांकेतिक   सांचकेतिता          No\n",
       "11     farmion        फर्मिऑन      आर्मिशन          No\n",
       "12      harana          हारना        हराना          No\n",
       "13   asaamnjsy      असामंजस्य     आसामंस्य          No\n",
       "14   polishing       पॉलिशिंग     सोलिशिंग          No\n",
       "15   niptaaraa        निपटारा     इनिपतारा          No\n",
       "16       robin          राबिन        सोबिन          No\n",
       "17        rigs          रिग्स        सिग्स          No\n",
       "18      airway          एयरवे        इयरवे          No\n",
       "19     garjana         गर्जना       उल्जना          No"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = []\n",
    "cor = []\n",
    "dec = []\n",
    "ex = []\n",
    "\n",
    "np.random.seed(10)\n",
    "for index in range(20):\n",
    "    seq_index = np.random.randint(len(test_X))\n",
    "    input_seq = test_X[seq_index]\n",
    "    decoded_sentence = translate(model, input_seq, input_char_index, output_char_index, reverse_input_char_index, \n",
    "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
    "              num_encoder_tokens, num_decoder_tokens, device)\n",
    "\n",
    "    if test_Y[seq_index][1:-1] == decoded_sentence:\n",
    "        ex.append(\"Yes\")\n",
    "    else:\n",
    "        ex.append(\"No\")        \n",
    "        \n",
    "    inp.append(input_seq)\n",
    "    cor.append(test_Y[seq_index][1:-1])\n",
    "    dec.append(decoded_sentence)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "grid = {'Input Word': inp, 'Correct Output' : cor, 'Decoded Word' : dec, \"Exact Match\" : ex}\n",
    "pd.DataFrame(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06885828520657486\n"
     ]
    }
   ],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "workbook = xlsxwriter.Workbook('predictions_vanilla_pytorch.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "worksheet.write(0, 0, \"Input Word\")\n",
    "worksheet.write(0, 1, \"Correct Output\")\n",
    "worksheet.write(0, 2, \"Decoded Word\")\n",
    "worksheet.write(0, 3, \"Exact Match\")\n",
    "\n",
    "total_words = len(test_X)\n",
    "correct_pred = 0\n",
    "\n",
    "for i in range(total_words):\n",
    "    \n",
    "    decoded_sentence = translate(model, test_X[i], input_char_index, output_char_index, reverse_input_char_index, \n",
    "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
    "              num_encoder_tokens, num_decoder_tokens, device)\n",
    "    \n",
    "    worksheet.write(i+1, 0, test_X[i])\n",
    "    worksheet.write(i+1, 1, test_Y[i])\n",
    "    worksheet.write(i+1, 2, decoded_sentence)\n",
    "    \n",
    "    if test_Y[i][1:-1] == decoded_sentence:\n",
    "        correct_pred += 1\n",
    "        worksheet.write(i+1, 3, \"Yes\")\n",
    "    else:\n",
    "        worksheet.write(i+1, 3, \"No\")\n",
    "        \n",
    "#     print(i)\n",
    "    \n",
    "test_accuracy = correct_pred / total_words\n",
    "\n",
    "print(test_accuracy)\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06885828520657486\n"
     ]
    }
   ],
   "source": [
    "total_words = len(test_X)\n",
    "correct_pred = 0\n",
    "\n",
    "for i in range(total_words):\n",
    "    \n",
    "    decoded_sentence = translate(model, test_X[i], input_char_index, output_char_index, reverse_input_char_index, \n",
    "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
    "              num_encoder_tokens, num_decoder_tokens, device)\n",
    "    \n",
    "    if test_Y[i][1:-1] == decoded_sentence:\n",
    "        correct_pred += 1\n",
    "\n",
    "#     print(i)\n",
    "    \n",
    "test_accuracy = correct_pred / total_words\n",
    "\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
