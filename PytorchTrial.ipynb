{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the train, validation and test dataset\n",
    "\n",
    "train_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.train.tsv'\n",
    "val_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.dev.tsv'\n",
    "test_path = 'dakshina_dataset_v1.0\\hi\\lexicons\\hi.translit.sampled.test.tsv'\n",
    "\n",
    "# creating the corpus and vectorizing the data\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "input_corpus = set()\n",
    "output_corpus = set()\n",
    "\n",
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    \n",
    "for line in lines[:len(lines) - 1]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    #using \"tab\" as the \"start sequence\" character for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    train_X.append(input_text)\n",
    "    train_Y.append(target_text)\n",
    "    for char in input_text:\n",
    "        input_corpus.add(char)\n",
    "    for char in target_text:\n",
    "        output_corpus.add(char)\n",
    "\n",
    "# ' ' is used to fill the empty spaces of shorter sequences\n",
    "input_corpus.add(\" \")\n",
    "output_corpus.add(\" \")\n",
    "input_corpus = sorted(list(input_corpus))\n",
    "output_corpus = sorted(list(output_corpus))\n",
    "num_encoder_tokens = len(input_corpus)\n",
    "num_decoder_tokens = len(output_corpus)\n",
    "max_encoder_seq_length = max([len(txt) for txt in train_X])\n",
    "max_decoder_seq_length = max([len(txt) for txt in train_Y])\n",
    "\n",
    "val_X = []\n",
    "val_Y = []\n",
    "with open(val_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "    \n",
    "for line in lines[:len(lines) - 1]:\n",
    "    target_text, input_text, _ = line.split(\"\\t\")\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    val_X.append(input_text)\n",
    "    val_Y.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 44204\n",
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 66\n",
      "Max sequence length for inputs: 20\n",
      "Max sequence length for outputs: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(train_X))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char_index = dict([(char, i) for i, char in enumerate(input_corpus)])\n",
    "output_char_index = dict([(char, i) for i, char in enumerate(output_corpus)])\n",
    "\n",
    "input_data = np.zeros((max_encoder_seq_length,len(train_X)), dtype=\"int64\")\n",
    "target_data = np.zeros((max_decoder_seq_length,len(train_X)), dtype=\"int64\")\n",
    "\n",
    "for i, (x, y) in enumerate(zip(train_X, train_Y)):\n",
    "    for t, char in enumerate(x):\n",
    "        input_data[t, i] = input_char_index[char]\n",
    "        \n",
    "    input_data[t + 1 :,i] = input_char_index[\" \"]\n",
    "    \n",
    "    for t, char in enumerate(y):\n",
    "        target_data[t, i] = output_char_index[char]\n",
    "            \n",
    "    target_data[t + 1 :,i] = output_char_index[\" \"]\n",
    "    \n",
    "input_data_val = np.zeros((max_encoder_seq_length,len(val_X)), dtype=\"int64\")\n",
    "target_data_val = np.zeros((max_decoder_seq_length,len(val_X)), dtype=\"int64\")\n",
    "\n",
    "for i, (x, y) in enumerate(zip(val_X, val_Y)):\n",
    "    for t, char in enumerate(x):\n",
    "        input_data_val[t, i] = input_char_index[char]\n",
    "        \n",
    "    input_data_val[t + 1 :,i] = input_char_index[\" \"]\n",
    "    \n",
    "    for t, char in enumerate(y):\n",
    "        target_data_val[t, i] = output_char_index[char]\n",
    "            \n",
    "    target_data_val[t + 1 :,i] = output_char_index[\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertin numpy arrays to tensors\n",
    "input_data = torch.tensor(input_data,dtype=torch.int64)\n",
    "target_data = torch.tensor(target_data,dtype=torch.int64)\n",
    "input_data_val = torch.tensor(input_data_val,dtype=torch.int64)\n",
    "target_data_val = torch.tensor(target_data_val,dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = num_decoder_tokens\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "input_size_encoder = num_encoder_tokens\n",
    "input_size_decoder = num_decoder_tokens\n",
    "output_size = num_decoder_tokens\n",
    "encoder_embedding_size = 64\n",
    "decoder_embedding_size = 64\n",
    "hidden_size = 128  # Needs to be the same for both RNN's\n",
    "num_enc_layers = 3\n",
    "num_dec_layers = 3\n",
    "enc_dropout = 0.1\n",
    "dec_dropout = 0.1\n",
    "training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_net = Encoder(\n",
    "    input_size_encoder, encoder_embedding_size, hidden_size, num_enc_layers, enc_dropout\n",
    ").to(device)\n",
    "\n",
    "decoder_net = Decoder(\n",
    "    input_size_decoder,\n",
    "    decoder_embedding_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    num_dec_layers,\n",
    "    dec_dropout,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is only for training, not to be used now as we have saved the model\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_ds_x = torch.split(input_data,batch_size,dim=1)\n",
    "train_ds_y = torch.split(target_data,batch_size,dim=1)\n",
    "input_data_val = input_data_val.to(device)\n",
    "target_data_val = target_data_val.to(device)\n",
    "target_val = target_data_val[1:].reshape(-1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    model.eval()\n",
    "    model.train()\n",
    "\n",
    "    for i, (x,y) in enumerate(zip(train_ds_x,train_ds_y)):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = x.to(device)\n",
    "        target = y.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin. While we're at it\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "torch.save(model.state_dict(),'models\\model_pytorch_noAT_state.pt')\n",
    "torch.save(model,'models\\model_pytorch_noAT.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (embedding): Embedding(27, 64)\n",
       "    (rnn): LSTM(64, 128, num_layers=3, dropout=0.1)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (embedding): Embedding(66, 64)\n",
       "    (rnn): LSTM(64, 128, num_layers=3, dropout=0.1)\n",
       "    (fc): Linear(in_features=128, out_features=66, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models\\model_pytorch_noAT_state.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_char_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in output_char_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, word, input_char_index, output_char_index, reverse_input_char_index, \n",
    "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
    "              num_encoder_tokens, num_decoder_tokens, device):\n",
    "    \n",
    "    word_t = ''\n",
    "    data = np.zeros((max_encoder_seq_length,1), dtype=\"int64\")\n",
    "    for t, char in enumerate(word):\n",
    "        data[t, 0] = input_char_index[char]\n",
    "        \n",
    "    data[t + 1 :,0] = input_char_index[\" \"]\n",
    "    \n",
    "    data = torch.tensor(data,dtype=torch.int64).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(data)\n",
    "        \n",
    "    x = torch.tensor(np.array(output_char_index['\\t']).reshape(1,)).to(device)\n",
    "\n",
    "    for t in range(1, max_decoder_seq_length):\n",
    "        output, hidden, cell = model.decoder(x, hidden, cell)\n",
    "        best_guess = output.argmax(1)\n",
    "        x = best_guess\n",
    "        ch = reverse_target_char_index[x.item()]\n",
    "        if ch == '\\n':\n",
    "            break\n",
    "        else:\n",
    "            word_t = word_t+ch\n",
    "\n",
    "    return word_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tअं\n",
      "\n",
      "अं\n",
      "\tअंकगणित\n",
      "\n",
      "अंकगणित\n",
      "\tअंकल\n",
      "\n",
      "अंकल\n",
      "\tअंकुर\n",
      "\n",
      "अंकुर\n",
      "\tअंकुरण\n",
      "\n",
      "अंकुरण\n",
      "\tअंकुरित\n",
      "\n",
      "अंकुरित\n",
      "\tअंकुश\n",
      "\n",
      "आंकुश\n",
      "\tअंकुश\n",
      "\n",
      "अंकुश\n",
      "\tअंग\n",
      "\n",
      "आंग\n",
      "\tअंग\n",
      "\n",
      "अंगा\n",
      "\tअंगद\n",
      "\n",
      "अगंध\n",
      "\tअंगद\n",
      "\n",
      "अंगद\n",
      "\tअंगने\n",
      "\n",
      "अंगने\n",
      "\tअंगभंग\n",
      "\n",
      "अंगभंग\n",
      "\tअंगरक्षक\n",
      "\n",
      "अंगरक्षक\n",
      "\tअंगरक्षक\n",
      "\n",
      "अंगरक्षक\n",
      "\tअंगारा\n",
      "\n",
      "अंगारा\n",
      "\tअंगारे\n",
      "\n",
      "अंगारे\n",
      "\tअंगारे\n",
      "\n",
      "अंगारे\n",
      "\tअंगी\n",
      "\n",
      "अंगी\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(train_Y[i])\n",
    "    print(translate(model, train_X[i], input_char_index, output_char_index, reverse_input_char_index, \n",
    "              reverse_target_char_index, max_encoder_seq_length, max_decoder_seq_length, \n",
    "              num_encoder_tokens, num_decoder_tokens, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
